{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Estimator Tutorial\n",
    "---\n",
    "## 이 문서의 내용:\n",
    "AWS Sagemaekr에서 Tensorflow를 사용하려면 Estimator API 형태로 코드 작성이 필요합니다.  \n",
    "이번 튜토리얼은 Sagemaker를 사용하기 전에 Estimator를 사용하는 것에 대해서 간단하게 살펴 볼 예정입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator api 특징\n",
    "Estimator를 사용해서 머신러닝 코드를 작성할시 Estimator는 아래와 같은 작업을 해줍니다.  \n",
    " - build the graph\n",
    " - initialize variables\n",
    " - start queues\n",
    " - handle exceptions\n",
    " - create checkpoint files and recover from failures\n",
    " - save summaries for TensorBoard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator 구성\n",
    "---\n",
    "```python\n",
    "# 어떤 input(feature)이 neural net에 전달될지 \n",
    "feature_columns = [tf.feature_column.numeric_column(\"inputs\", shape=[2])]\n",
    "\n",
    "# nerual net 구성\n",
    "classifier = tf.estimator.DNNClassifier()\n",
    "\n",
    "# train or evaluation 시 사용할 input function (위에서 정의한 feature column과 동일한 key 값을 가진 data를 return해 주어야 한다.)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn()\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xor input data\n",
    "---\n",
    "XOR 문제에 대한 input 값은 아래 4개 입니다.\n",
    "\n",
    "```\n",
    "0 ^ 0 = 0\n",
    "0 ^ 1 = 1\n",
    "1 ^ 0 = 1\n",
    "1 ^ 1 = 0\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### directory 구조는 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data-set   \n",
    "---\n",
    "학습에 사용할 데이터를 읽어 옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "\n",
    "train_set = np.loadtxt('data/xor_train.csv', delimiter=',')\n",
    "test_set = np.loadtxt('data/xor_test.csv', delimiter=',')\n",
    "print(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep neural network 구성\n",
    "---\n",
    "Estimator api는 predefined model을 가지고 있습니다. 이번에는 그중 *DNNClassifier*를 사용해보겠습니다.  \n",
    "(Custom model도 Estimator로 작성 및 사용 가능함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 사용될 feature\n",
    "feature_columns = [tf.feature_column.numeric_column(\"inputs\", shape=[2])]\n",
    "\n",
    "# 10 x 20 x 10 의 neural net 구성\n",
    "classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                        hidden_units=[10, 20, 10],\n",
    "                                        n_classes=2,\n",
    "                                        model_dir=\"model\",\n",
    "                                        config=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`feature_columns=feature_columns.` XOR의 결과는 2개의 binary 값으로 결정 되므로 type은 numeric value, shpae는 [2]로 정의했습니다.   \n",
    "\n",
    "\n",
    "`hidden_units=[10, 20, 10]` 3개의 hidden layer를 설정했습니다.    \n",
    "\n",
    "\n",
    "`n_classes=2` 결과는 0또는 1 이므로 2로 값을 설정 했습니다.  \n",
    "\n",
    "\n",
    "`model_dir=model` checkpoint data 와 TensorBoard summaries 가 저장되는 위치  \n",
    "\n",
    "\n",
    "`config` None으로 할시 default config가 적용된다.  \n",
    "\n",
    "\n",
    "config 에서는 checkpoint값을 시간 or step별로 주기를 지정하거나 cluster spec등을 설정해줄 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input function 작성\n",
    "---\n",
    "*tf.estimator* api는 input function을 사용합니다.  \n",
    "input pipeline을 작성을 위해서 *tf.estimator.inputs.numpy_input_fn* 을 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training inputs\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"inputs\": train_set[:, 0:-1]},\n",
    "    y=np.array(train_set[:, [-1]]),\n",
    "    num_epochs=None,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.train(input_fn=train_input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training inputs\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"inputs\": test_set[:, 0:-1]},\n",
    "    y=np.array(test_set[:, [-1]]),\n",
    "    num_epochs=10,\n",
    "    shuffle=True)\n",
    "\n",
    "# Evaluate accuracy.\n",
    "accuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "\n",
    "print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
